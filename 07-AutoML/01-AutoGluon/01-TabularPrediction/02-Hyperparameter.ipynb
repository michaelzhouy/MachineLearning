{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08ba1b48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T12:11:56.642531Z",
     "start_time": "2021-06-28T12:11:54.661257Z"
    }
   },
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9194ac24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T12:12:23.994170Z",
     "start_time": "2021-06-28T12:11:56.644974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age workclass  fnlwgt      education  education-num  \\\n",
      "6118    51   Private   39264   Some-college             10   \n",
      "23204   58   Private   51662           10th              6   \n",
      "29590   40   Private  326310   Some-college             10   \n",
      "18116   37   Private  222450        HS-grad              9   \n",
      "33964   62   Private  109190      Bachelors             13   \n",
      "\n",
      "            marital-status        occupation    relationship    race      sex  \\\n",
      "6118    Married-civ-spouse   Exec-managerial            Wife   White   Female   \n",
      "23204   Married-civ-spouse     Other-service            Wife   White   Female   \n",
      "29590   Married-civ-spouse      Craft-repair         Husband   White     Male   \n",
      "18116        Never-married             Sales   Not-in-family   White     Male   \n",
      "33964   Married-civ-spouse   Exec-managerial         Husband   White     Male   \n",
      "\n",
      "       capital-gain  capital-loss  hours-per-week  native-country   class  \n",
      "6118              0             0              40   United-States    >50K  \n",
      "23204             0             0               8   United-States   <=50K  \n",
      "29590             0             0              44   United-States   <=50K  \n",
      "18116             0          2339              40     El-Salvador   <=50K  \n",
      "33964         15024             0              40   United-States    >50K  \n",
      "Summary of occupation column: \n",
      " count                  500\n",
      "unique                  15\n",
      "top        Exec-managerial\n",
      "freq                    77\n",
      "Name: occupation, dtype: object\n"
     ]
    }
   ],
   "source": [
    "train_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv')\n",
    "subsample_size = 500  # subsample subset of data for faster demo, try setting this to much larger values\n",
    "train_data = train_data.sample(n=subsample_size, random_state=0)\n",
    "print(train_data.head())\n",
    "\n",
    "label = 'occupation'\n",
    "print(\"Summary of occupation column: \\n\", train_data['occupation'].describe())\n",
    "\n",
    "new_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv')\n",
    "test_data = new_data[5000:].copy()  # this should be separate data in your applications\n",
    "y_test = test_data[label]\n",
    "test_data_nolabel = test_data.drop(columns=[label])  # delete label column\n",
    "val_data = new_data[:5000].copy() # 验证集\n",
    "\n",
    "metric = 'accuracy' # we specify eval-metric just for demo (unnecessary as it's the default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a980463",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T12:14:17.724037Z",
     "start_time": "2021-06-28T12:12:23.996751Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20210628_121224/\"\n",
      "Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n",
      "Beginning AutoGluon training ... Time limit = 120s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20210628_121224/\"\n",
      "AutoGluon Version:  0.2.0\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 14\n",
      "Tuning Data Rows:    5000\n",
      "Tuning Data Columns: 14\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\tFirst 10 (of 15) unique label values:  [' Exec-managerial', ' Other-service', ' Craft-repair', ' Sales', ' Prof-specialty', ' Protective-serv', ' ?', ' Adm-clerical', ' Machine-op-inspct', ' Tech-support']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 12 out of 15 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.978\n",
      "Train Data Class Count: 12\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    210343.37 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.11 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 8 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\t\t('int', [])      : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.3 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.16s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Hyperparameter tuning model: LightGBM ...\n",
      "/root/anaconda3/lib/python3.6/site-packages/fsspec/__init__.py:47: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
      "  for spec in entry_points.get(\"fsspec.specs\", []):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "750cba998e594aec9f6edd83c8081712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>TqdmHBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTime limit exceeded\n",
      "Fitted model: LightGBM/T0 ...\n",
      "\t0.3033\t = Validation accuracy score\n",
      "\t22.35s\t = Training runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitted model: LightGBM/T1 ...\n",
      "\t0.2729\t = Validation accuracy score\n",
      "\t28.62s\t = Training runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Hyperparameter tuning model: NeuralNetMXNet ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3adb727de750462ca33f128ac01400b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>TqdmHBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTime limit exceeded\n",
      "Fitted model: NeuralNetMXNet/T0 ...\n",
      "\t0.1704\t = Validation accuracy score\n",
      "\t11.27s\t = Training runtime\n",
      "\t0.95s\t = Validation runtime\n",
      "Fitted model: NeuralNetMXNet/T1 ...\n",
      "\t0.1333\t = Validation accuracy score\n",
      "\t11.21s\t = Training runtime\n",
      "\t1.07s\t = Validation runtime\n",
      "Fitted model: NeuralNetMXNet/T2 ...\n",
      "\t0.1359\t = Validation accuracy score\n",
      "\t11.15s\t = Training runtime\n",
      "\t0.89s\t = Validation runtime\n",
      "Fitted model: NeuralNetMXNet/T3 ...\n",
      "\t0.2264\t = Validation accuracy score\n",
      "\t12.14s\t = Training runtime\n",
      "\t1.05s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 119.84s of the 7.69s of remaining time.\n",
      "\t0.3135\t = Validation accuracy score\n",
      "\t1.37s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 113.7s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20210628_121224/\")\n"
     ]
    }
   ],
   "source": [
    "import autogluon.core as ag\n",
    "\n",
    "nn_options = {  # specifies non-default hyperparameter values for neural network models\n",
    "    'num_epochs': 10,  # number of training epochs (controls training time of NN models)\n",
    "    'learning_rate': ag.space.Real(1e-4, 1e-2, default=5e-4, log=True),  # learning rate used in training (real-valued hyperparameter searched on log-scale)\n",
    "    'activation': ag.space.Categorical('relu', 'softrelu', 'tanh'),  # activation function used in NN (categorical hyperparameter, default = first entry)\n",
    "    'layers': ag.space.Categorical([100], [1000], [200, 100], [300, 200, 100]),  # each choice for categorical hyperparameter 'layers' corresponds to list of sizes for each NN layer to use\n",
    "    'dropout_prob': ag.space.Real(0.0, 0.5, default=0.1),  # dropout probability (real-valued hyperparameter)\n",
    "}\n",
    "\n",
    "gbm_options = {  # specifies non-default hyperparameter values for lightGBM gradient boosted trees\n",
    "    'num_boost_round': 100,  # number of boosting rounds (controls training time of GBM models)\n",
    "    'num_leaves': ag.space.Int(lower=26, upper=66, default=36),  # number of leaves in trees (integer hyperparameter)\n",
    "}\n",
    "\n",
    "hyperparameters = {  # hyperparameters of each model type\n",
    "                   'GBM': gbm_options,\n",
    "                   'NN': nn_options,  # NOTE: comment this line out if you get errors on Mac OSX\n",
    "                  }  # When these keys are missing from hyperparameters dict, no models of that type are trained\n",
    "\n",
    "time_limit = 2 * 60  # train various models for ~2 min\n",
    "num_trials = 5  # try at most 5 different hyperparameter configurations for each type of model\n",
    "search_strategy = 'auto'  # to tune hyperparameters using Bayesian optimization routine with a local scheduler\n",
    "\n",
    "hyperparameter_tune_kwargs = {  # HPO is not performed unless hyperparameter_tune_kwargs is specified\n",
    "    'num_trials': num_trials,\n",
    "    'scheduler' : 'local',\n",
    "    'searcher': search_strategy,\n",
    "}\n",
    "\n",
    "predictor = TabularPredictor(label=label, eval_metric=metric).fit(\n",
    "    train_data, tuning_data=val_data, time_limit=time_limit,\n",
    "    hyperparameters=hyperparameters, hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5acdee1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T12:14:26.513336Z",
     "start_time": "2021-06-28T12:14:17.726512Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:   [' Exec-managerial', ' Craft-repair', ' Craft-repair', ' Other-service', ' Craft-repair']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: accuracy on test data: 0.2885300901656532\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.2885300901656532\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "y_pred = predictor.predict(test_data_nolabel)\n",
    "print(\"Predictions:  \", list(y_pred)[:5])\n",
    "perf = predictor.evaluate(test_data, auxiliary_metrics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e65cd82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T12:14:27.105026Z",
     "start_time": "2021-06-28T12:14:26.520833Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2   0.313512       4.159989  98.109442                0.001482           1.368279            2       True          7\n",
      "1          LightGBM/T0   0.303260       0.090943  22.352601                0.090943          22.352601            1       True          1\n",
      "2          LightGBM/T1   0.272914       0.111888  28.624230                0.111888          28.624230            1       True          2\n",
      "3    NeuralNetMXNet/T3   0.226369       1.050502  12.140137                1.050502          12.140137            1       True          6\n",
      "4    NeuralNetMXNet/T0   0.170392       0.947632  11.266991                0.947632          11.266991            1       True          3\n",
      "5    NeuralNetMXNet/T2   0.135944       0.888370  11.150436                0.888370          11.150436            1       True          5\n",
      "6    NeuralNetMXNet/T1   0.133279       1.069173  11.206769                1.069173          11.206769            1       True          4\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'WeightedEnsembleModel', 'LGBModel', 'TabularNeuralNetModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', []) : 8 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "('int', [])      : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "Plot summary of models saved to file: AutogluonModels/ag-20210628_121224/SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    }
   ],
   "source": [
    "results = predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bd04960",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T12:14:47.949142Z",
     "start_time": "2021-06-28T12:14:27.106704Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20210628_121427/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20210628_121427/\"\n",
      "AutoGluon Version:  0.2.0\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 14\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\tFirst 10 (of 15) unique label values:  [' Exec-managerial', ' Other-service', ' Craft-repair', ' Sales', ' Prof-specialty', ' Protective-serv', ' ?', ' Adm-clerical', ' Machine-op-inspct', ' Tech-support']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 12 out of 15 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.978\n",
      "Train Data Class Count: 12\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    209882.82 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.28 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 8 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\t\t('int', [])      : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.13s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\t0.3067\t = Validation accuracy score\n",
      "\t2.01s\t = Training runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_BAG_L1 ...\n",
      "\t0.1063\t = Validation accuracy score\n",
      "\t7.02s\t = Training runtime\n",
      "\t0.88s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.3108\t = Validation accuracy score\n",
      "\t0.23s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\t0.2863\t = Validation accuracy score\n",
      "\t1.67s\t = Training runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_BAG_L2 ...\n",
      "\t0.0879\t = Validation accuracy score\n",
      "\t7.28s\t = Training runtime\n",
      "\t0.9s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.2863\t = Validation accuracy score\n",
      "\t0.23s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 20.82s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20210628_121427/\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=label, eval_metric=metric).fit(train_data,\n",
    "    num_bag_folds=5,  # num_bag_folds k折交叉验证多少次\n",
    "    num_bag_sets=1, num_stack_levels=1,\n",
    "    hyperparameters = {'NN': {'num_epochs': 2}, 'GBM': {'num_boost_round': 20}},  # last  argument is just for quick demo here, omit it in real applications\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d374c6ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T12:14:59.374810Z",
     "start_time": "2021-06-28T12:14:47.950801Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:   [' Exec-managerial', ' Sales', ' Craft-repair', ' Adm-clerical', ' ?']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: accuracy on test data: 0.2814007129377228\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.2814007129377228\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "y_pred = predictor.predict(test_data_nolabel)\n",
    "print(\"Predictions:  \", list(y_pred)[:5])\n",
    "perf = predictor.evaluate(test_data, auxiliary_metrics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f164b91b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T12:14:59.486554Z",
     "start_time": "2021-06-28T12:14:59.381539Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                   model  score_val  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0    WeightedEnsemble_L2   0.310838       1.024340   9.257577                0.000692           0.231300            2       True          3\n",
      "1        LightGBM_BAG_L1   0.306748       0.142460   2.006487                0.142460           2.006487            1       True          1\n",
      "2        LightGBM_BAG_L2   0.286299       1.139725  10.697642                0.116076           1.671364            2       True          4\n",
      "3    WeightedEnsemble_L3   0.286299       1.140403  10.926354                0.000678           0.228712            3       True          6\n",
      "4  NeuralNetMXNet_BAG_L1   0.106339       0.881189   7.019791                0.881189           7.019791            1       True          2\n",
      "5  NeuralNetMXNet_BAG_L2   0.087935       1.927694  16.310957                0.904046           7.284679            2       True          5\n",
      "Number of models trained: 6\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_LGB', 'StackerEnsembleModel_TabularNeuralNet', 'WeightedEnsembleModel'}\n",
      "Bagging used: True  (with 5 folds)\n",
      "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', []) : 8 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "('int', [])      : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "Plot summary of models saved to file: AutogluonModels/ag-20210628_121427/SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    }
   ],
   "source": [
    "results = predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "919c3187",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T12:15:20.432600Z",
     "start_time": "2021-06-28T12:14:59.489401Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"agModels-predictOccupation\"\n",
      "Beginning AutoGluon training ... Time limit = 30s\n",
      "AutoGluon will save models to \"agModels-predictOccupation/\"\n",
      "AutoGluon Version:  0.2.0\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 14\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\tFirst 10 (of 15) unique label values:  [' Exec-managerial', ' Other-service', ' Craft-repair', ' Sales', ' Prof-specialty', ' Protective-serv', ' ?', ' Adm-clerical', ' Machine-op-inspct', ' Tech-support']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 12 out of 15 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.978\n",
      "Train Data Class Count: 12\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    209898.9 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.28 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 8 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\t\t('int', [])      : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.12s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 29.88s of the 29.88s of remaining time.\n",
      "\t0.3067\t = Validation accuracy score\n",
      "\t1.87s\t = Training runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 27.79s of the 27.79s of remaining time.\n",
      "\t0.0532\t = Validation accuracy score\n",
      "\t7.49s\t = Training runtime\n",
      "\t1.0s\t = Validation runtime\n",
      "Repeating k-fold bagging: 2/20\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 19.26s of the 19.26s of remaining time.\n",
      "\t0.3149\t = Validation accuracy score\n",
      "\t3.52s\t = Training runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 17.43s of the 17.43s of remaining time.\n",
      "\t0.0716\t = Validation accuracy score\n",
      "\t14.69s\t = Training runtime\n",
      "\t1.88s\t = Validation runtime\n",
      "Completed 2/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 29.88s of the 9.29s of remaining time.\n",
      "\t0.3149\t = Validation accuracy score\n",
      "\t0.21s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 20.93s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-predictOccupation/\")\n"
     ]
    }
   ],
   "source": [
    "save_path = 'agModels-predictOccupation'  # folder where to store trained models\n",
    "\n",
    "predictor = TabularPredictor(label=label, eval_metric=metric, path=save_path).fit(\n",
    "    train_data, auto_stack=True,\n",
    "    time_limit=30, hyperparameters={'NN': {'num_epochs': 2}, 'GBM': {'num_boost_round': 20}}  # last 2 arguments are for quick demo, omit them in real applications\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24767342",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T12:15:20.438639Z",
     "start_time": "2021-06-28T12:15:20.434256Z"
    }
   },
   "outputs": [],
   "source": [
    "predictor = TabularPredictor.load(save_path)  # `predictor.path` is another way to get the relative path needed to later load predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fee5ca6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T12:15:20.880944Z",
     "start_time": "2021-06-28T12:15:20.440109Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      age workclass  fnlwgt      education  education-num marital-status  \\\n",
      "5000   49   Private  259087   Some-college             10       Divorced   \n",
      "\n",
      "        relationship    race      sex  capital-gain  capital-loss  \\\n",
      "5000   Not-in-family   White   Female             0             0   \n",
      "\n",
      "      hours-per-week  native-country   class  \n",
      "5000              40   United-States   <=50K  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5000     Exec-managerial\n",
       "Name: occupation, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapoint = test_data_nolabel.iloc[[0]]  # Note: .iloc[0] won't work because it returns pandas Series instead of DataFrame\n",
    "print(datapoint)\n",
    "predictor.predict(datapoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d1c0870",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T12:15:21.267185Z",
     "start_time": "2021-06-28T12:15:20.888302Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>?</th>\n",
       "      <th>Adm-clerical</th>\n",
       "      <th>Armed-Forces</th>\n",
       "      <th>Craft-repair</th>\n",
       "      <th>Exec-managerial</th>\n",
       "      <th>Farming-fishing</th>\n",
       "      <th>Handlers-cleaners</th>\n",
       "      <th>Machine-op-inspct</th>\n",
       "      <th>Other-service</th>\n",
       "      <th>Priv-house-serv</th>\n",
       "      <th>Prof-specialty</th>\n",
       "      <th>Protective-serv</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Tech-support</th>\n",
       "      <th>Transport-moving</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>0.038825</td>\n",
       "      <td>0.165695</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.134694</td>\n",
       "      <td>0.229323</td>\n",
       "      <td>0.015379</td>\n",
       "      <td>0.034922</td>\n",
       "      <td>0.050433</td>\n",
       "      <td>0.061511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089848</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104733</td>\n",
       "      <td>0.017316</td>\n",
       "      <td>0.057322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ?   Adm-clerical   Armed-Forces   Craft-repair   Exec-managerial  \\\n",
       "5000  0.038825       0.165695            0.0       0.134694          0.229323   \n",
       "\n",
       "       Farming-fishing   Handlers-cleaners   Machine-op-inspct  \\\n",
       "5000          0.015379            0.034922            0.050433   \n",
       "\n",
       "       Other-service   Priv-house-serv   Prof-specialty   Protective-serv  \\\n",
       "5000        0.061511               0.0         0.089848               0.0   \n",
       "\n",
       "         Sales   Tech-support   Transport-moving  \n",
       "5000  0.104733       0.017316           0.057322  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict_proba(datapoint)  # returns a DataFrame that shows which probability corresponds to which class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea2ab87a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T12:15:21.283418Z",
     "start_time": "2021-06-28T12:15:21.274463Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LightGBM_BAG_L1'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.get_model_best()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa52410f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T12:15:32.422637Z",
     "start_time": "2021-06-28T12:15:21.290743Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>0.283498</td>\n",
       "      <td>0.314928</td>\n",
       "      <td>0.340698</td>\n",
       "      <td>0.311854</td>\n",
       "      <td>3.515773</td>\n",
       "      <td>0.340698</td>\n",
       "      <td>0.311854</td>\n",
       "      <td>3.515773</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.283498</td>\n",
       "      <td>0.314928</td>\n",
       "      <td>0.343772</td>\n",
       "      <td>0.312542</td>\n",
       "      <td>3.726311</td>\n",
       "      <td>0.003074</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>0.210538</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NeuralNetMXNet_BAG_L1</td>\n",
       "      <td>0.122038</td>\n",
       "      <td>0.071575</td>\n",
       "      <td>10.599440</td>\n",
       "      <td>1.883255</td>\n",
       "      <td>14.688040</td>\n",
       "      <td>10.599440</td>\n",
       "      <td>1.883255</td>\n",
       "      <td>14.688040</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model  score_test  score_val  pred_time_test  \\\n",
       "0        LightGBM_BAG_L1    0.283498   0.314928        0.340698   \n",
       "1    WeightedEnsemble_L2    0.283498   0.314928        0.343772   \n",
       "2  NeuralNetMXNet_BAG_L1    0.122038   0.071575       10.599440   \n",
       "\n",
       "   pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0       0.311854   3.515773                 0.340698                0.311854   \n",
       "1       0.312542   3.726311                 0.003074                0.000688   \n",
       "2       1.883255  14.688040                10.599440                1.883255   \n",
       "\n",
       "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0           3.515773            1       True          1  \n",
       "1           0.210538            2       True          3  \n",
       "2          14.688040            1       True          2  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data, silent=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
