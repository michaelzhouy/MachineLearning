# 深度学习中的注意力机制
[深度学习中的注意力机制](https://blog.csdn.net/tg229dvt5i93mxaq5a6u/article/details/78422216)


## 人类的视觉注意力
1. 深度学习中的注意力机制从本质上讲和人类的选择性视觉注意力机制类似, 核心目标也是从众多信息中选择出对当前任务目标更关键的信息.

## Encoder-Decoder框架
1. 文本处理领域的Encoder-Decoder框架可以这么直观地去理解: 可以把它看作适合处理由一个句子(或篇章)生成另外一个句子(或篇章)的通用处理模型. 对于句子对<Source, Target>, 我们的目标是给定输入句子Source, 期待通过Encoder-Decoder框架来生成目标句子Target. Source和Target可以是同一种语言, 也可以是两种不同的语言(机器翻译). 而Source和Target分别由各自的单词序列构成:
$$Source = <x_1, x_2, ..., x_m> \\
Target = <y_1, y_2, ..., y_m>$$

2. Encoder: 对输入句子Source进行编码, 将输入句子通过非线性变换转化为中间语义表示C:
$$C = F(x_1, x_2, ..., x_m)$$

3. Decoder: 其任务是根据句子Source的中间语义表示C和之前已经生成的历史信息$y_1, y_2, ..., y_{i-1}$来生成`i`时刻要生成的单词:
$$y_i = G(C, y_1, y_2, ..., y_{i-1})$$

4. 每个$y_i$都依次这么产生, 那么看起来就是整个系统根据输入句子Source生成了目标句子Target. 

5. 应用: 一般而言, 文本处理和语音识别的Encoder部分通常采用RNN模型, 图像处理的Encoder一般采用CNN模型.
- 文本领域
  - 机器翻译: 如果Source是中文句子, Target是英文句子，那么这就是解决机器翻译问题的Encoder-Decoder框架
  - 文本摘要: 如果Source是一篇文章, Target是概括性的几句描述语句, 那么这是文本摘要的Encoder-Decoder框架
  - 问答系统: 如果Source是一句问句, Target是一句回答, 那么这是问答系统或者对话机器人的Encoder-Decoder框架.
- 语音识别: Encoder部分的输入是语音流, 输出是对应的文本信息
- 图像描述: Encoder部分的输入是一副图片, Decoder的输出是能够描述图片语义内容的一句描述语

## Attention模型
### Soft Attention模型
1. 上述的Encoder-Decoder框架是没有体现出"注意力模型"的, 所以可以把它看作是注意力不集中的分心模型. 为什么说它注意力不集中呢?请观察下目标句子Target中每个单词的生成过程如下:
$$y_1 = G(C)\\y_2 = G(C, y1)\\y_3 = G(C, y_1, y_2)$$
其中, G是Decode的非线性变换函数.

2. 可以看出, 在生成目标句子的单词时, 不论生成哪个单词, 它们使用的输入句子Source的语义编码C都是一样的，没有任何区别

3. 语义编码C是由句子Source的每个单词经过Encoder编码产生的, 这意味着不论是生成哪个单词$y1, y2$, 还是$y3$, 其实句子Source中任意单词对生成某个目标单词$y_i$来说, 影响力都是相同的, 这是为何说这个模型没有体现出注意力的缘由. 这类似于人类看到眼前的画面, 但是眼中却没有注意焦点一样.

举例说明:
1. 如果拿机器翻译来解释这个分心模型的Encoder-Decoder框架更好理解, 比如输入的是英文句子: `Tom chase Jerry`, Encoder-Decoder框架逐步生成中文单词: "汤姆", "追逐", "杰瑞".

2. 在翻译"杰瑞"这个中文单词的时候, 分心模型里面的每个英文单词对于翻译目标单词"杰瑞"贡献是相同的, 很明显这里不太合理, 显然"Jerry"对于翻译成"杰瑞"更重要, 但是分心模型是无法体现这一点的, 这就是为何说它没有引入注意力的原因.

3. 没有引入注意力的模型在输入句子比较短的时候问题不大, 但是如果输入句子比较长, 此时所有语义完全通过一个中间语义向量来表示, 单词自身的信息已经消失, 可想而知会丢失很多细节信息, 这也是为何要引入注意力模型的重要原因.

4. 上面的例子中, 如果引入Attention模型的话, 应该在翻译"杰瑞"的时候, 体现出英文单词对于翻译当前中文单词影响的不同程度, 比如给出类似下面一个概率分布值:
$$(Tom, 0.3), (Chase, 0.2), (Jerry, 0.5)$$

每个英文单词的概率代表了翻译当前单词"杰瑞"时, 注意力分配模型分配给不同英文单词的注意力大小. 这对于正确翻译目标语单词肯定是有帮助的, 因为引入了新的信息.

5. 同理, 目标句子中的每个单词都应该学会其对应的源语句子中单词的注意力分配概率信息. 这意味着在生成每个单词的时候, 原先都是相同的中间语义表示$C$会被替换成根据当前生成单词而不断变化的. 理解Attention模型的关键就是这里, 即由固定的中间语义表示$C$换成了根据当前输出单词来调整成加入注意力模型的变化的$C_i$.
$$y_1 = G(C1)\\y_2 = G(C2, y_1)\\y_3 = G(C3, y_1, y_2)$$

6. 每个$C_i$可能对应着不同的源语句子单词的注意力分配概率分布, 比如对于上面的英汉翻译来说, 其对应的信息可能如下:
$$C_{汤姆}=G(0.6 \times F(Tom), 0.2 \times F(Chase), 0.2 * F(Jerry))\\
C_{追逐}=G(0.2 \times F(Tom), 0.7 \times F(Chase), 0.1 * F(Jerry))\\
C_{杰瑞}=G(0.3 \times F(Tom), 0.2 \times F(Chase), 0.5 * F(Jerry))$$

其中, F函数代表Encoder对输入英文单词的某种变换函数, 比如如果Encoder是用的RNN模型的话, 这个F函数的结果往往是某个时刻输入后隐层节点的状态值; G代表Encoder根据单词的中间表示合成整个句子中间语义表示的变换函数, 一般的做法中, g函数就是对构成元素加权求和, 即下列公式:
$$C_i=\sum_{j=1}^{L_x}\alpha_{ij}h_j$$

其中, $L_x$代表输入句子Source的长度, $\alpha_{ij}$代表在Target输出第$i$个单词时Source输入句子中第$j$个单词的注意力分配系数, 而$h_j$则是Source输入句子中第$j$个单词的语义编码. 假设$C_i$下标$i$就是上面例子所说的"汤姆", 那么$L_x$就是3, $h_1 = F(Tom), h_2 = F(Chase), h_3 = F(Jerry)$分别是输入句子每个单词的语义编码, 对应的注意力模型权值则分别是0.6, 0.2, 0.2, 所以G函数本质上就是个加权求和函数.
