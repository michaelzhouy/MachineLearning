# 经验误差与过拟合

1.  错误率：分类错误的样本数占样本总数的比例，$m$个样本中有$a$个样本分类错误，即错误率$E=a/m$，精度$acc=1-a/m$

2.  误差：学习器的实际预测输出与样本的真实输出之间的差异称为“误差”。学习器在训练集上的误差称为“训练误差”或“经验误差”，在新样本上的误差称为“泛化误差”

3.  过拟合、欠拟合

    ![](https://i.loli.net/2018/10/17/5bc7181172996.png)

---
# 评估方法

1.  我们希望使用一个测试集的测试误差作为泛化误差的近似，因而需要对数据进行有效的划分，划分出互斥的训练集和测试集

## 留出法

1.  将数据集$D$划分出两个互斥的集合$S$（训练集）和$T$（测试集），即$D=S\bigcup D, S\bigcap T=\emptyset$，在$S$上训练出模型后，用$T$来评估其测试误差，作为对泛化误差的估计
2.  训练/测试集的划分要尽可能保持数据分布的一致性，采用分层抽样
3.  由于划分的随机性，单次使用留出法得到的估计结果也往往不够稳定，一般采用多次随机划分取平均的做法
4.  一般，将大约==2/3~4/5==的样本用于训练，剩余样本用于测试

## 交叉验证法

1.  “交叉验证法”，首先将数据集$D$划分成$k$个大小相似的互斥子集，即$D=D_1\bigcup D_2\bigcup ...\bigcup D_k, D_i\bigcap D_j=\emptyset(i\neq j)$
2.  每个子集$D_i$尽可能保持数据分布的一致性，即从$D$中分层采样得到
3.  每次用$k-1$个子集的并集作为训练集，余下的那个子集作为测试集，这样就可获得$k$组训练/测试集，并行$k$次训练和测试，最终返回的是这$k$个测试结果的均值
4.  $p$次$k$交叉验证

## 自助法

1.  我们希望是用$D$训练出来的模型。但在留出法和交叉验证法中，由于保留了一部分样本用于测试，因此实际评估的模型所使用的训练集比$D$小，就是引入一些因训练样本规模不同而导致的估计偏差。留一法受训练样本规模变化的影响较小，但是计算复杂度由太高，“自助法”是一个比较好的解决方案

2.  自助法：对于样本大小为$m$的数据集$D$，做有放回采样，重复m次，得到包含m个样本的数据集$D'$。

3.  通过自采样，初始数据集$D$中大约有$36.8%$的样本没有出现在$D'$中，于是将$D'$作为训练集，$D\D'$作为测试集

4.  自助法产生的数据集改变了初始数据集的分布，这会引入估计偏差

## 调参与最终模型
1. 算法的参数，又称超参数
2. 模型的参数
3. 将训练集划分为训练集和验证集，用验证集来进行模型选择和调参，最后用整个训练集重新训练模型，并提交

---

## 性能度量

