# 经验误差与过拟合

1.  错误率：分类错误的样本数占样本总数的比例，$m$个样本中有$a$个样本分类错误，即错误率$E=a/m$，精度$acc=1-a/m$
2.  误差：学习器的实际预测输出与样本的真实输出之间的差异称为“误差”。学习器在训练集上的误差称为“训练误差”或“经验误差”，在新样本上的误差称为“泛化误差”
3.  过拟合、欠拟合

---
# 评估方法

1.  我们希望使用一个测试集的测试误差作为泛化误差的近似，因而需要对数据进行有效的划分，划分出互斥的训练集和测试集

## 留出法

1.  将数据集$D$划分出两个互斥的集合$S$（训练集）和$T$（测试集），即$D=S\bigcup D, S\bigcap T=\emptyset$，在$S$上训练出模型后，用$T$来评估其测试误差，作为对泛化误差的估计
2.  训练/测试集的划分要尽可能保持数据分布的一致性，采用分层抽样
3.  由于划分的随机性，单次使用留出法得到的估计结果也往往不够稳定，一般采用多次随机划分取平均的做法
4.  一般，将大约==2/3~4/5==的样本用于训练，剩余样本用于测试

## 交叉验证法

1.  “交叉验证法”，首先将数据集$D$划分成$k$个大小相似的互斥子集，即$D=D_1\bigcup D_2\bigcup ...\bigcup D_k, D_i\bigcap D_j=\emptyset(i\neq j)$
2.  每个子集$D_i$尽可能保持数据分布的一致性，即从$D$中分层采样得到
3.  每次用$k-1$个子集的并集作为训练集，余下的那个子集作为测试集，这样就可获得$k$组训练/测试集，并行$k$次训练和测试，最终返回的是这$k$个测试结果的均值
4.  $p$次$k$交叉验证

## 自助法

1.  